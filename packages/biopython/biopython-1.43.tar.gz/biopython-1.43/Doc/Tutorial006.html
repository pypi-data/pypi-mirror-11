<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
            "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>

<META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<META name="GENERATOR" content="hevea 1.07">
<TITLE>
Advanced
</TITLE>
</HEAD>
<BODY >
<A HREF="Tutorial005.html"><IMG SRC ="previous_motif.gif" ALT="Previous"></A>
<A HREF="index.html"><IMG SRC ="contents_motif.gif" ALT="Up"></A>
<A HREF="Tutorial007.html"><IMG SRC ="next_motif.gif" ALT="Next"></A>
<HR>

<H1><A NAME="htoc69">Chapter&nbsp;5</A>&nbsp;&nbsp;Advanced</H1>
<A NAME="toc28"></A>
<H2><A NAME="htoc70">5.1</A>&nbsp;&nbsp;Sequence Class</H2>
<A NAME="toc29"></A>
<H2><A NAME="htoc71">5.2</A>&nbsp;&nbsp;Regression Testing Framework</H2>
<A NAME="sec:regr_test"></A>
Biopython has a regression testing framework written Andrew Dalke and ported to PyUnit by Brad Chapman which helps us make sure the code is as bug-free as possible before going out.<BR>
<BR>

<H3><A NAME="htoc72">5.2.1</A>&nbsp;&nbsp;Writing a Regression Test</H3>
Every module that goes into Biopython should have a test (and should also have documentation!). Let's say you've written a new module called Biospam -- here is what you should do to make a regression test:
<OL type=1><LI>
 Write a script called <CODE>test_Biospam.py</CODE>
<UL><LI>This script should live in the Tests directory<BR>
<BR>
<LI>The script should test all of the important functionality of the module (the more you test the better your test is, of course!).
 </UL><BR>
<BR>
<LI>If the script requires files to do the testing, these should go in
 the directory Tests/Biospam.<BR>
<BR>
<LI>Write out the test output and verify the output to be correct. 
 There are two ways to do this:
<OL type=a><LI>
 The long way:
<UL><LI>Run the script and write its output to a file. On UNIX machines,
 you would do something like: <CODE>python test_Biospam.py &gt; test_Biospam</CODE> which would write the output to the file <CODE>test_Biospam</CODE>.<BR>
<BR>
<LI>Manually look at the file <CODE>test_Biospam</CODE> to make sure the output is correct. When you are sure it is all right and there are no bugs, you need to quickly edit the <CODE>test_Biospam</CODE> file so that the first line is: '<CODE>test_Biospam</CODE>' (no quotes).<BR>
<BR>
<LI>copy the <CODE>test_Biospam</CODE> file to the directory Tests/output</UL><BR>
<BR>
<LI>The quick way:
<UL><LI>
 Run <CODE>python run_tests.py -g test_Biospam.py</CODE>. The
 regression testing framework is nifty enough that it'll put
 the output in the right place in just the way it likes it. <BR>
<BR>
<LI>Go to the output (which should be in <CODE>Tests/output/test_Biospam</CODE>) and double check the output to make sure it is all correct. </UL></OL><BR>
<BR>
<LI>Now change to the Tests directory and run the regression tests
 with <CODE>python run_tests.py</CODE>. This will run all of the tests, and
 you should see your test run (and pass!).<BR>
<BR>
<LI>That's it! Now you've got a nice test for your module.
 Congratulations!
</OL>
<A NAME="toc30"></A>
<H2><A NAME="htoc73">5.3</A>&nbsp;&nbsp;Parser Design</H2>

<H3><A NAME="htoc74">5.3.1</A>&nbsp;&nbsp;Design Overview</H3>
Many of the Biopython parsers are built around an event-oriented design that includes
Scanner and Consumer objects.<BR>
<BR>
Scanners take input from a data source and analyze it line by line,
sending off an event whenever it recognizes some information in the
data. For example, if the data includes information about an organism
name, the scanner may generate an <CODE>organism_name</CODE> event whenever it
encounters a line containing the name.<BR>
<BR>
Consumers are objects that receive the events generated by Scanners.
Following the previous example, the consumer receives the
<CODE>organism_name</CODE> event, and the processes it in whatever manner
necessary in the current application.<BR>
<BR>

<H3><A NAME="htoc75">5.3.2</A>&nbsp;&nbsp;Events</H3>
There are two types of events: info events that tag the location of
information within a data stream, and section events that mark
sections within a stream. Info events are associated with specific
lines within the data, while section events are not.<BR>
<BR>
Section event names must be in the format <CODE>start_EVENTNAME</CODE> and
<CODE>end_EVENTNAME</CODE> where <CODE>EVENTNAME</CODE> is the name of the event.<BR>
<BR>
For example, a FASTA-formatted sequence scanner may generate the
following events:
<PRE>
EVENT NAME      ORIGINAL INPUT
begin_sequence  
title           &gt;gi|132871|sp|P19947|RL30_BACSU 50S RIBOSOMAL PROTEIN L30 (BL27
sequence        MAKLEITLKRSVIGRPEDQRVTVRTLGLKKTNQTVVHEDNAAIRGMINKVSHLVSVKEQ
end_sequence
begin_sequence
title           &gt;gi|132679|sp|P19946|RL15_BACSU 50S RIBOSOMAL PROTEIN L15
sequence        MKLHELKPSEGSRKTRNRVGRGIGSGNGKTAGKGHKGQNARSGGGVRPGFEGGQMPLFQRLPK
sequence        RKEYAVVNLDKLNGFAEGTEVTPELLLETGVISKLNAGVKILGNGKLEKKLTVKANKFSASAK
sequence        GTAEVI
end_sequence
[...]
</PRE>
(I cut the lines shorter so they'd look nicer in my editor).<BR>
<BR>
The FASTA scanner generated the following events: <CODE>title</CODE>, <CODE>sequence</CODE>,
<CODE>begin_sequence</CODE>, and <CODE>end_sequence</CODE>. Note that the <CODE>begin_sequence</CODE>
and <CODE>end_sequence</CODE> events are not associated with any line in the
original input. They are used to delineate separate sequences within
the file.<BR>
<BR>
The events a scanner can send must be specifically defined for each
data format.<BR>
<BR>

<H3><A NAME="htoc76">5.3.3</A>&nbsp;&nbsp;'noevent' EVENT</H3>
A data file can contain lines that have no meaningful information,
such as blank lines. By convention, a scanner should generate the
"noevent" event for these lines.<BR>
<BR>

<H3><A NAME="htoc77">5.3.4</A>&nbsp;&nbsp;Scanners</H3>
<PRE>
class Scanner:
    def feed(self, handle, consumer):
        # Implementation
</PRE>
Scanners should implement a method named 'feed' that takes a file
handle and a consumer. The scanner should read data from the file
handle and generate appropriate events for the consumer.<BR>
<BR>

<H3><A NAME="htoc78">5.3.5</A>&nbsp;&nbsp;Consumers</H3>
<PRE>
class Consumer:
    # event handlers
</PRE>
Consumers contain methods that handle events. The name of the method
is the event that it handles. Info events are passed the line of the
data containing the information, and section events are passed
nothing.<BR>
<BR>
You are free to ignore events that are not interesting for your
application. You should just not implement methods for those events.<BR>
<BR>
All consumers should be derived from the base Consumer class.<BR>
<BR>
An example:
<PRE>
class FASTAConsumer(Consumer):
    def title(self, line):
        # do something with the title
    def sequence(self, line):
        # do something with the sequence
    def begin_sequence(self):
        # a new sequence starts
    def end_sequence(self):
        # a sequence ends
</PRE>

<H3><A NAME="htoc79">5.3.6</A>&nbsp;&nbsp;BLAST</H3>
BLAST Scanners produce the following events:
<PRE>
header
    version
    reference
    query_info
    database_info

descriptions
    description_header
    round                         psi blast
    model_sequences               psi blast
    nonmodel_sequences            psi blast
    converged                     psi blast
    description
    no_hits

alignment
    multalign                     master-slave
    title                         pairwise
    length                        pairwise
  hsp
    score                         pairwise
    identities                    pairwise
    strand                        pairwise, blastn
    frame                         pairwise, blastx, tblastn, tblastx
    query                         pairwise
    align                         pairwise
    sbjct                         pairwise

database_report
    database
    posted_date
    num_letters_in_database
    num_sequences_in_database
    num_letters_searched          RESERVED.  Currently unused.  I've never
    num_sequences_searched        RESERVED.  seen it, but it's in blastool.c..
    ka_params
    gapped                        not blastp
    ka_params_gap                 gapped mode (not tblastx)

parameters
    matrix
    gap_penalties                 gapped mode (not tblastx)
    num_hits                      
    num_sequences                 
    num_extends                   
    num_good_extends              
    num_seqs_better_e
    hsps_no_gap                   gapped (not tblastx) and not blastn
    hsps_prelim_gapped            gapped (not tblastx) and not blastn
    hsps_prelim_gap_attempted     gapped (not tblastx) and not blastn
    hsps_gapped                   gapped (not tblastx) and not blastn
    query_length
    database_length
    effective_hsp_length
    effective_query_length
    effective_database_length
    effective_search_space
    effective_search_space_used
    frameshift                    blastx or tblastn or tblastx
    threshold
    window_size
    dropoff_1st_pass
    gap_x_dropoff
    gap_x_dropoff_final           gapped (not tblastx) and not blastn
    gap_trigger
    blast_cutoff
</PRE>

<H3><A NAME="htoc80">5.3.7</A>&nbsp;&nbsp;Enzyme</H3>
The Enzyme.py module works with the enzyme.dat file included with the
Enzyme distribution.
The Enzyme Scanner produces the following events:
<PRE>
record
    identification
    description
    alternate_name
    catalytic_activity
    cofactor
    comment
    disease
    prosite_reference
    databank_reference
    terminator
</PRE>

<H3><A NAME="htoc81">5.3.8</A>&nbsp;&nbsp;KEGG</H3>

<H4>5.3.8.1&nbsp;&nbsp;Bio.KEGG.Enzyme</H4>
The Bio.KEGG.Enzyme module works with the 'enzyme' file from the
Ligand database, which can be obtained from the KEGG project. 
(<A HREF="http://www.genome.ad.jp/kegg"><TT>http://www.genome.ad.jp/kegg</TT></A>).<BR>
<BR>
The Bio.KEGG.Enzyme.Record contains all the information stored in
a KEGG/Enzyme record. Its string representation also is a valid KEGG
record, but it is NOT guaranteed to be equivalent to the record
from which it was produced.<BR>
<BR>
The Bio.KEGG.Enzyme.Scanner produces the following events:
<PRE>
entry 
name 
classname
sysname
reaction
substrate
product
inhibitor 
cofactor
effector
comment 
pathway_db 
pathway_id
pathway_desc
organism 
gene_id
disease_db
disease_id 
disease_desc
motif_db
motif_id
motif
structure_db 
structure_id
dblinks_db
dblinks_id
record_end
</PRE>

<H4>5.3.8.2&nbsp;&nbsp;Bio.KEGG.Compound</H4>
The Bio.KEGG.Compound module works with the 'compound' file from the
Ligand database, which can be obtained from the KEGG project. 
(<A HREF="http://www.genome.ad.jp/kegg"><TT>http://www.genome.ad.jp/kegg</TT></A>).<BR>
<BR>
The Bio.KEGG.Compound.Record contains all the information stored in
a KEGG/Compound record. Its string representation also is a valid KEGG
record, but it is NOT guaranteed to be equivalent to the record
from which it was produced.<BR>
<BR>
The Bio.KEGG.Enzyme.Scanner produces the following events:
<PRE>
entry 
name 
formula 
pathway_db 
pathway_id
pathway_desc
enzyme_id
enzyme_role
structure_db 
structure_id
dblinks_db
dblinks_id
record_end
</PRE>

<H3><A NAME="htoc82">5.3.9</A>&nbsp;&nbsp;Fasta</H3>
The Fasta.py module works with FASTA-formatted sequence data.
The Fasta Scanner produces the following events:
<PRE>
sequence
    title
    sequence
</PRE>

<H3><A NAME="htoc83">5.3.10</A>&nbsp;&nbsp;Medline</H3>
The Online Services Reference Manual documents the MEDLINE format at:
<A HREF="http://www.nlm.nih.gov/pubs/osrm_nlm.html"><TT>http://www.nlm.nih.gov/pubs/osrm_nlm.html</TT></A><BR>
<BR>
The Medline scanner produces the following events:
<PRE>
record
    undefined
    abstract_author
    abstract
    address
    author
    call_number
    comments
    class_update_date
    country
    entry_date
    publication_date
    english_abstract
    entry_month
    gene_symbol
    identification
    issue_part_supplement
    issn
    journal_title_code
    language
    special_list
    last_revision_date
    mesh_heading
    mesh_tree_number
    major_revision_date
    no_author
    substance_name
    pagination
    personal_name_as_subject
    publication_type
    number_of_references
    cas_registry_number
    record_originator
    journal_subset
    subheadings
    secondary_source_id
    source
    title_abbreviation
    title
    transliterated_title
    unique_identifier
    volume_issue
    year
    pubmed_id
</PRE>
undefined is a special event that is called for every line with a
qualifier not defined in the specification.<BR>
<BR>

<H3><A NAME="htoc84">5.3.11</A>&nbsp;&nbsp;Prosite</H3>
The Prosite scanner produces the following events:
<PRE>
copyrights
    copyright
record
    identification
    accession
    date
    description
    pattern
    matrix
    rule
    numerical_results
    comment
    database_reference
    pdb_reference
    documentation
    terminator
</PRE>
The PRODOC scanner produces the following events:
<PRE>
record
    accession
    prosite_reference
    text
    reference
</PRE>

<H3><A NAME="htoc85">5.3.12</A>&nbsp;&nbsp;SWISS-PROT</H3>
The SProt.py module works with the sprotXX.dat file included with the
SwissProt distribution.
The SProt Scanner produces the following events:
<PRE>
record
    identification
    accession
    date
    description
    gene_name
    organism_species
    organelle
    organism_classification
    reference_number
    reference_position
    reference_comment
    reference_cross_reference
    reference_author
    reference_title
    reference_location
    comment
    database_cross_reference
    keyword
    feature_table
    sequence_header
    sequence_data
    terminator
</PRE>
The KeyWList.py modules works with the keywlist.txt file included with
the SwissProt distribution.
The KeyWList scanner produces the following events:
<PRE>
header
keywords
    keyword
footer
    copyright
</PRE>

<H3><A NAME="htoc86">5.3.13</A>&nbsp;&nbsp;NBRF</H3>
The NBRF module works with NBRF-formatted sequence data. Data is available at:
<A HREF="http://www-nbrf.georgetown.edu/pirwww/pirhome.shtml"><TT>http://www-nbrf.georgetown.edu/pirwww/pirhome.shtml</TT></A>.<BR>
<BR>
The NBRF Scanner produces the following events:
<PRE>
    sequence_type
    sequence_name
    comment
    sequence
</PRE>

<H3><A NAME="htoc87">5.3.14</A>&nbsp;&nbsp;Ndb</H3>
The Ndb module works with Ndb-formatted sequence data. Data is available at:
<A HREF="http://ndbserver.rutgers.edu/NDB/NDBATLAS/index.html"><TT>http://ndbserver.rutgers.edu/NDB/NDBATLAS/index.html</TT></A>.<BR>
<BR>
The Ndb record contains the following items:
<PRE>
        Id
        Features
        Name
        Sequence
        Citation
        Space Group
        Cell Constants
        Crystallization Conditions
        Refinement
        Coordinates
</PRE>
Sequence is an instance of Crystal which is dictionary of Chain objects. Each chain is a sequence of PDB hetero items. Citation is a list of Reference objects. Crystal, Reference, Chain and Hetero are part of the biopython distribution.<BR>
<BR>

<H3><A NAME="htoc88">5.3.15</A>&nbsp;&nbsp;MetaTool</H3>
The MetaTool parser works with MetaTool output files. MetaTool implements algorithms to decompose a biochemical pathway into a combination of simpler networks that are more accessible to analysis.<BR>
<BR>
The MetaTool web page is <A HREF="http://pinguin.biologie.uni-jena.de/bioinformatik/networks/"><TT>http://pinguin.biologie.uni-jena.de/bioinformatik/networks/</TT></A>.<BR>
<BR>
The MetaTool parser requires Numeric Python. Information is available at
<A HREF="http://numpy.scipy.org/#older_array"><TT>http://numpy.scipy.org/#older_array</TT></A>.<BR>
<BR>
The Bio.MetaTool.Scanner produces the following events:
<PRE>
input_file_name
num_int_metabolites
num_reactions
metabolite_line
unbalanced_metabolite
num_rows
num_cols
irreversible_vector
branch_metabolite
non_branch_metabolite
stoichiometric_tag
kernel_tag
subsets_tag
reduced_system_tag
convex_basis_tag
conservation_relations_tag
elementary_modes_tag
reaction
enzyme
matrix_row
sum_is_constant_line
end_stochiometric
end_kernel
end_subsets
end_reduced_system
end_convex_basis
end_conservation_relations
end_elementary_modes
</PRE>
<A NAME="toc31"></A>
<H2><A NAME="htoc89">5.4</A>&nbsp;&nbsp;Substitution Matrices</H2>

<H3><A NAME="htoc90">5.4.1</A>&nbsp;&nbsp;SubsMat</H3>
This module provides a class and a few routines for generating substitution matrices, similar to BLOSUM or PAM matrices, but based on user-provided data.<BR>
<BR>
Additionally, you may select a matrix from MatrixInfo.py, a collection of established substitution matrices.
<PRE>
class SeqMat(UserDict.UserDict)
</PRE>
<OL type=1><LI>
 Attributes
<OL type=a><LI>
 <CODE>self.data</CODE>: a dictionary in the form of <CODE>{(i1,j1):n1, (i1,j2):n2,...,(ik,jk):nk}</CODE> where i, j are alphabet letters, and n is a value.<BR>
<BR>
<LI><CODE>self.alphabet</CODE>: a class as defined in Bio.Alphabet<BR>
<BR>
<LI><CODE>self.ab_list</CODE>: a list of the alphabet's letters, sorted. Needed mainly for internal purposes<BR>
<BR>
<LI><CODE>self.sum_letters</CODE>: a dictionary. <CODE>{i1: s1, i2: s2,...,in:sn}</CODE> where:
 <OL type=i><LI>
 i: an alphabet letter; 
 <LI>s: sum of all values in a half-matrix for that letter; 
 <LI>n: number of letters in alphabet.
 </OL>
 </OL><BR>
<BR>
<LI>Methods
<OL type=a><LI><PRE> 
__init__(self,data=None,alphabet=None,
         mat_type=NOTYPE,mat_name='',build_later=0):
</PRE>
 <OL type=i><LI><CODE>data</CODE>: can be either a dictionary, or another SeqMat instance.
 <LI><CODE>alphabet</CODE>: a Bio.Alphabet instance. If not provided, construct an alphabet from data.<BR>
<BR>
<LI><CODE>mat_type</CODE>: type of matrix generated. One of the following:
<DL COMPACT=compact><DT>
 <B>NOTYPE</B><DD> No type defined
 <DT><B>ACCREP</B><DD> Accepted Replacements Matrix
 <DT><B>OBSFREQ</B><DD> Observed Frequency Matrix 
 <DT><B>EXPFREQ</B><DD> Expsected Frequency Matrix
 <DT><B>SUBS</B><DD> Substitution Matrix 
 <DT><B>LO</B><DD> Log Odds Matrix
 </DL><BR>
<BR>
<CODE>mat_type</CODE> is provided automatically by some of SubsMat's functions.<BR>
<BR>
<LI><CODE>mat_name</CODE>: matrix name, such as "BLOSUM62" or "PAM250"<BR>
<BR>
<LI><CODE>build_later</CODE>: default false. If true, user may supply only alphabet and empty dictionary, if intending to build the matrix later. this skips the sanity check of alphabet size vs. matrix size. </OL><BR>
<BR>
<LI><PRE>
entropy(self,obs_freq_mat)
</PRE>
 <OL type=i><LI>
 <CODE>obs_freq_mat</CODE>: an observed frequency matrix. Returns the matrix's entropy, based on the frequency in <CODE>obs_freq_mat</CODE>. The matrix instance should be LO or SUBS.
 </OL><BR>
<BR>
<LI><PRE>
letter_sum(self,letter)
</PRE>
 Returns the sum of all values in the matrix, for the provided <CODE>letter</CODE><BR>
<BR>
<LI><PRE>
all_letters_sum(self)
</PRE>Fills the dictionary attribute <CODE>self.sum_letters</CODE> with the sum of values for each letter in the matrix's alphabet.<BR>
<BR>
<LI><PRE>
print_mat(self,f,format="%4d",bottomformat="%4s",alphabet=None)
</PRE>
 prints the matrix to file handle f. <CODE>format</CODE> is the format field for the matrix values; <CODE>bottomformat</CODE> is the format field for the bottom row, containing matrix letters. Example output for a 3-letter alphabet matrix:
<PRE>
A 23
B 12 34
C 7  22  27
  A   B   C
</PRE>
 The <CODE>alphabet</CODE> optional argument is a string of all characters in the alphabet. If supplied, the order of letters along the axes is taken from the string, rather than by alphabetical order.</OL><BR>
<BR>
<LI>Usage<BR>
<BR>
The following section is layed out in the order by which most people wish to generate a log-odds matrix. Of course, interim matrices can be generated and
 investigated. Most people just want a log-odds matrix, that's all. 
<OL type=a><LI>Generating an Accepted Replacement Matrix<BR>
<BR>
Initially, you should generate an accepted replacement matrix (ARM) from your data. The values in ARM are the counted number of replacements according to your data. The data could be a set of pairs or multiple alignments. So for instance if Alanine was replaced by Cysteine 10 times, and Cysteine by Alanine 12 times, the corresponding ARM entries would be: 
<PRE>
('A','C'): 10, ('C','A'): 12 
</PRE>
as order doesn't matter, user can already provide only one entry: 
<PRE>
('A','C'): 22 
</PRE>
 A SeqMat instance may be initialized with either a full (first method of counting: 10, 12) or half (the latter method, 22) matrices. A full protein
 alphabet matrix would be of the size 20x20 = 400. A half matrix of that alphabet would be 20x20/2 + 20/2 = 210. That is because same-letter entries don't
 change. (The matrix diagonal). Given an alphabet size of N: 
<OL type=i><LI>
 Full matrix size:N*N <BR>
<BR>
<LI>Half matrix size: N(N+1)/2 
 </OL><BR>
The SeqMat constructor automatically generates a half-matrix, if a full matrix is passed. If a half matrix is passed, letters in the key should be provided in alphabetical order: ('A','C') and not ('C',A'). <BR>
<BR>
At this point, if all you wish to do is generate a log-odds matrix, please go to the section titled Example of Use. The following text describes the nitty-gritty of internal functions, to be used by people who wish to investigate their nucleotide/amino-acid frequency data more thoroughly. <BR>
<BR>
<LI>Generating the observed frequency matrix (OFM)<BR>
<BR>
Use:
<PRE>
OFM = SubsMat._build_obs_freq_mat(ARM)
</PRE>
 The OFM is generated from the ARM, only instead of replacement counts, it contains replacement frequencies. <BR>
<BR>
<LI>Generating an expected frequency matrix (EFM)<BR>
<BR>
Use:
<PRE>
EFM = SubsMat._build_exp_freq_mat(OFM,exp_freq_table)
</PRE>
 <OL type=i><LI>
 <CODE>exp_freq_table</CODE>: should be a FreqTable instance. See section&nbsp;<A HREF="#sec:freq_table">5.4.2</A> for detailed information on FreqTable. Briefly, the expected frequency table has the frequencies of appearance for each member of the alphabet. It is
 implemented as a dictionary with the alphabet letters as keys, and each letter's frequency as a value. Values sum to 1.
 </OL><BR>
The expected frequency table can (and generally should) be generated from the observed frequency matrix. So in most cases you will generate <CODE>exp_freq_table</CODE> using:
<PRE>
&gt;&gt;&gt; exp_freq_table = SubsMat._exp_freq_table_from_obs_freq(OFM)
&gt;&gt;&gt; EFM = SubsMat._build_exp_freq_mat(OFM,exp_freq_table)
</PRE>
But you can supply your own <CODE>exp_freq_table</CODE>, if you wish<BR>
<BR>
<LI>Generating a substitution frequency matrix (SFM)<BR>
<BR>
Use:
<PRE>
SFM = SubsMat._build_subs_mat(OFM,EFM)
</PRE>
 Accepts an OFM, EFM. Provides the division product of the corresponding values. <BR>
<BR>
<LI>Generating a log-odds matrix (LOM)<BR>
<BR>
Use: 
<PRE>
LOM=SubsMat._build_log_odds_mat(SFM[,logbase=10,factor=10.0,round_digit=1])
</PRE>
 <OL type=i><LI>
 Accepts an SFM. <BR>
<BR>
<LI><CODE>logbase</CODE>: base of the logarithm used to generate the log-odds values. <BR>
<BR>
<LI><CODE>factor</CODE>: factor used to multiply the log-odds values. Each entry is generated by log(LOM[key])*factor And rounded to the <CODE>round_digit</CODE> place after the decimal point, if required.</OL></OL><BR>
<BR>
<LI>Example of use<BR>
<BR>
As most people would want to generate a log-odds matrix, with minimum hassle, SubsMat provides one function which does it all:
<PRE> 
make_log_odds_matrix(acc_rep_mat,exp_freq_table=None,logbase=10,
                      factor=10.0,round_digit=0):
</PRE>
<OL type=a><LI>
 <CODE>acc_rep_mat</CODE>: user provided accepted replacements matrix
 <LI><CODE>exp_freq_table</CODE>: expected frequencies table. Used if provided, if not, generated from the <CODE>acc_rep_mat</CODE>.
 <LI><CODE>logbase</CODE>: base of logarithm for the log-odds matrix. Default base 10.
 <LI><CODE>round_digit</CODE>: number after decimal digit to which result should be rounded. Default zero.
</OL></OL>

<H3><A NAME="htoc91">5.4.2</A>&nbsp;&nbsp;FreqTable</H3>
<A NAME="sec:freq_table"></A>
<PRE>
FreqTable.FreqTable(UserDict.UserDict)
</PRE>
<OL type=1><LI>Attributes:
<OL type=a><LI>
 <CODE>alphabet</CODE>: A Bio.Alphabet instance.<BR>
<BR>
<LI><CODE>data</CODE>: frequency dictionary<BR>
<BR>
<LI><CODE>count</CODE>: count dictionary (in case counts are provided).
 </OL><BR>
<BR>
<LI>Functions:
<OL type=a><LI>
 <CODE>read_count(f)</CODE>: read a count file from stream f. Then convert to frequencies<BR>
<BR>
<LI><CODE>read_freq(f)</CODE>: read a frequency data file from stream f. Of course, we then don't have the counts, but it is usually the letter frquencies which are interesting.</OL><BR>
<BR>
<LI>Example of use:<BR>
<BR>
The expected count of the residues in the database is sitting in a file, whitespace delimited, in the following format (example given for a 3-letter alphabet):
<PRE>
A   35
B   65
C   100
</PRE>
And will be read using the <CODE>FreqTable.read_count(file_handle)</CODE> function. <BR>
<BR>
An equivalent frequency file:
<PRE>
A  0.175
B  0.325
C  0.5 
</PRE>
Conversely, the residue frequencies or counts can be passed as a dictionary. 
Example of a count dictionary (3-letter alphabet):
<PRE>
{'A': 35, 'B': 65, 'C': 100}
</PRE>
Which means that an expected data count would give a 0.5 frequency 
for 'C', a 0.325 probability of 'B' and a 0.175 probability of 'A' 
out of 200 total, sum of A, B and C)<BR>
<BR>
A frequency dictionary for the same data would be:
<PRE>
{'A': 0.175, 'B': 0.325, 'C': 0.5}
</PRE>
Summing up to 1.<BR>
<BR>
When passing a dictionary as an argument, you should indicate whether it is a count or a frequency dictionary. Therefore the FreqTable class constructor requires two arguments: the dictionary itself, and FreqTable.COUNT or FreqTable.FREQ indicating counts or frequencies, respectively.<BR>
<BR>
Read expected counts. readCount will already generate the frequencies
Any one of the following may be done to geerate the frequency table (ftab):
<PRE>
&gt;&gt;&gt; from SubsMat import *
&gt;&gt;&gt; ftab = FreqTable.FreqTable(my_frequency_dictionary,FreqTable.FREQ)
&gt;&gt;&gt; ftab = FreqTable.FreqTable(my_count_dictionary,FreqTable.COUNT)
&gt;&gt;&gt; ftab = FreqTable.read_count(open('myCountFile'))
&gt;&gt;&gt; ftab = FreqTable.read_frequency(open('myFrequencyFile'))
</PRE></OL>
<HR>
<A HREF="Tutorial005.html"><IMG SRC ="previous_motif.gif" ALT="Previous"></A>
<A HREF="index.html"><IMG SRC ="contents_motif.gif" ALT="Up"></A>
<A HREF="Tutorial007.html"><IMG SRC ="next_motif.gif" ALT="Next"></A>
</BODY>
</HTML>
