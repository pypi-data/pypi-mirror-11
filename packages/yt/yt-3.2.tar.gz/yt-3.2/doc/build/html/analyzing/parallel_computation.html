<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Parallel Computation With yt &mdash; The yt Project 3.2-dev documentation</title>
    
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/bootswatch-3.3.4/readable/bootstrap.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '3.2-dev',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-3.3.4/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-sphinx.js"></script>
    <link rel="top" title="The yt Project 3.2-dev documentation" href="../index.html" />
    <link rel="up" title="General Data Analysis" href="index.html" />
    <link rel="next" title="Topic-Specific Analysis Modules" href="analysis_modules/index.html" />
    <link rel="prev" title="Time Series Analysis" href="time_series_analysis.html" />
    
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

    <script type="text/javascript">

      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-391373-2']);
      _gaq.push(['_setDomainName', 'yt-project.org']);
      _gaq.push(['_setAllowHash', false]);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();

    </script>
  </head>
  <body role="document">

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html"><img src="../_static/yt_icon.png">
          The yt Project</a>
        <span class="navbar-text navbar-version pull-left"><b>3.2</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../help/index.html">How to get help</a></li>
                <li><a href="../quickstart/index.html">Quickstart notebooks</a></li>
                <li><a href="../cookbook/index.html">Cookbook</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installing.html">Getting and Installing yt</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../installing.html#getting-yt">Getting yt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../installing.html#testing-your-installation">Testing Your Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../installing.html#switching-between-yt-2-x-and-yt-3-x">Switching between yt-2.x and yt-3.x</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../quickstart/index.html">yt Quickstart</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../quickstart/introduction.html">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../quickstart/data_inspection.html">Data Inspection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../quickstart/simple_visualization.html">Simple Visualization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../quickstart/data_objects_and_time_series.html">Data Objects and Time Series</a></li>
<li class="toctree-l2"><a class="reference internal" href="../quickstart/derived_fields_and_profiles.html">Derived Fields and Profiles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../quickstart/volume_rendering.html">Volume Rendering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../yt3differences.html">What&#8217;s New and Different in yt 3.0?</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../yt3differences.html#updating-to-yt-3-0-from-old-versions-and-going-back">Updating to yt 3.0 from Old Versions (and going back)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../yt3differences.html#converting-old-scripts-to-work-with-yt-3-0">Converting Old Scripts to Work with yt 3.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../yt3differences.html#cool-new-things">Cool New Things</a></li>
<li class="toctree-l2"><a class="reference internal" href="../yt3differences.html#api-changes">API Changes</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../cookbook/index.html">The Cookbook</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../cookbook/index.html#getting-the-sample-data">Getting the Sample Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbook/index.html#example-scripts">Example Scripts</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbook/index.html#example-notebooks">Example Notebooks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../visualizing/index.html">Visualizing Data</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../visualizing/plots.html">How to Make Plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../visualizing/callbacks.html">Plot Modifications: Overplotting Contours, Velocities, Particles, and More</a></li>
<li class="toctree-l2"><a class="reference internal" href="../visualizing/manual_plotting.html">Using the Manual Plotting Interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="../visualizing/volume_rendering.html">Volume Rendering: Making 3D Photorealistic Isocontoured Images</a></li>
<li class="toctree-l2"><a class="reference internal" href="../visualizing/hardware_volume_rendering.html">Hardware Volume Rendering on NVidia Graphics cards</a></li>
<li class="toctree-l2"><a class="reference internal" href="../visualizing/sketchfab.html">3D Surfaces and Sketchfab</a></li>
<li class="toctree-l2"><a class="reference internal" href="../visualizing/mapserver.html">Mapserver - A Google-Maps-like Interface to your Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../visualizing/streamlines.html">Streamlines: Tracking the Trajectories of Tracers in your Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../visualizing/colormaps/index.html">Colormaps</a></li>
<li class="toctree-l2"><a class="reference internal" href="../visualizing/writing_fits_images.html">Writing FITS Images</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">General Data Analysis</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="fields.html">Fields in yt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../developing/creating_derived_fields.html">Creating Derived Fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="objects.html">Data Objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="units/index.html">Symbolic Units</a></li>
<li class="toctree-l2"><a class="reference internal" href="filtering.html">Filtering your Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="generating_processed_data.html">Generating Processed Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="time_series_analysis.html">Time Series Analysis</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="">Parallel Computation With yt</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="analysis_modules/index.html">Topic-Specific Analysis Modules</a><ul>
<li class="toctree-l2"><a class="reference internal" href="analysis_modules/halo_analysis.html">Halo Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="analysis_modules/synthetic_observation.html">Synthetic Observation</a></li>
<li class="toctree-l2"><a class="reference internal" href="analysis_modules/exporting.html">Exporting to External Radiation Transport Codes</a></li>
<li class="toctree-l2"><a class="reference internal" href="analysis_modules/two_point_functions.html">Two Point Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="analysis_modules/clump_finding.html">Clump Finding</a></li>
<li class="toctree-l2"><a class="reference internal" href="analysis_modules/particle_trajectories.html">Particle Trajectories</a></li>
<li class="toctree-l2"><a class="reference internal" href="analysis_modules/ellipsoid_analysis.html">Halo Ellipsoid Analysis</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../examining/index.html">Loading and Examining Data</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../examining/loading_data.html">Loading Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examining/generic_array_data.html">Loading Generic Array Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examining/generic_particle_data.html">Loading Generic Particle Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examining/spherical_data.html">Loading Spherical Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examining/low_level_inspection.html">Low-Level Data Inspection: Accessing Raw Data</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../developing/index.html">Developing in yt</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../developing/intro.html">Getting Involved</a></li>
<li class="toctree-l2"><a class="reference internal" href="../developing/developing.html">How to Develop yt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../developing/building_the_docs.html">Documentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../developing/testing.html">Testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../developing/debugdrive.html">Debugging yt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../developing/creating_datatypes.html">Creating Data Objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="../developing/creating_derived_fields.html">Creating Derived Fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="../developing/creating_derived_quantities.html">Creating Derived Quantities</a></li>
<li class="toctree-l2"><a class="reference internal" href="../developing/creating_frontend.html">Creating A New Code Frontend</a></li>
<li class="toctree-l2"><a class="reference internal" href="../developing/external_analysis.html">Using yt with External Analysis Tools</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../reference/index.html">Reference Materials</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../reference/code_support.html">Code Support</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reference/command-line.html">Command-Line Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reference/api/api.html">API Reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reference/configuration.html">Customizing yt: The Configuration and Plugin Files</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reference/field_list.html">Field List</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reference/changelog.html">ChangeLog</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../faq/index.html">Frequently Asked Questions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../faq/index.html#version-installation">Version &amp; Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq/index.html#code-errors-and-failures">Code Errors and Failures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq/index.html#units">Units</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq/index.html#fields">Fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq/index.html#data-objects">Data Objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq/index.html#developing">Developing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq/index.html#miscellaneous">Miscellaneous</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../help/index.html">Getting Help</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../help/index.html#don-t-panic-and-don-t-give-up">Don&#8217;t panic and don&#8217;t give up</a></li>
<li class="toctree-l2"><a class="reference internal" href="../help/index.html#update-to-the-latest-version">Update to the latest version</a></li>
<li class="toctree-l2"><a class="reference internal" href="../help/index.html#search-the-documentation-faq-and-mailing-lists">Search the documentation, FAQ, and mailing lists</a></li>
<li class="toctree-l2"><a class="reference internal" href="../help/index.html#look-at-the-source-code">Look at the source code</a></li>
<li class="toctree-l2"><a class="reference internal" href="../help/index.html#isolate-and-document-your-problem">Isolate and document your problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../help/index.html#go-on-irc-to-ask-a-question">Go on IRC to ask a question</a></li>
<li class="toctree-l2"><a class="reference internal" href="../help/index.html#ask-the-mailing-list">Ask the mailing list</a></li>
<li class="toctree-l2"><a class="reference internal" href="../help/index.html#submit-a-bug-report">Submit a bug report</a></li>
<li class="toctree-l2"><a class="reference internal" href="../help/index.html#special-issues">Special Issues</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../about/index.html">About yt</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../about/index.html#what-is-yt">What is yt?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../about/index.html#who-is-yt">Who is yt?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../about/index.html#history-of-yt">History of yt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../about/index.html#how-do-i-contact-yt">How do I contact yt?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../about/index.html#how-do-i-cite-yt">How do I cite yt?</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Parallel Computation With yt</a><ul>
<li><a class="reference internal" href="#capabilities">Capabilities</a></li>
<li><a class="reference internal" href="#setting-up-parallel-yt">Setting Up Parallel yt</a></li>
<li><a class="reference internal" href="#running-a-yt-script-in-parallel">Running a yt Script in Parallel</a><ul>
<li><a class="reference internal" href="#how-do-i-run-my-yt-job-on-a-subset-of-available-processes">How do I run my yt job on a subset of available processes</a></li>
<li><a class="reference internal" href="#creating-parallel-and-serial-sections-in-a-script">Creating Parallel and Serial Sections in a Script</a></li>
</ul>
</li>
<li><a class="reference internal" href="#types-of-parallelism">Types of Parallelism</a><ul>
<li><a class="reference internal" href="#spatial-decomposition">Spatial Decomposition</a></li>
<li><a class="reference internal" href="#grid-decomposition">Grid Decomposition</a></li>
<li><a class="reference internal" href="#parallelization-over-multiple-objects-and-datasets">Parallelization over Multiple Objects and Datasets</a><ul>
<li><a class="reference internal" href="#use-of-piter">Use of <code class="docutils literal"><span class="pre">piter()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#parallelizing-over-multiple-objects">Parallelizing over Multiple Objects</a></li>
<li><a class="reference internal" href="#parallelization-over-multiple-datasets-including-time-series">Parallelization over Multiple Datasets (including Time Series)</a></li>
<li><a class="reference internal" href="#parallel-performance-resources-and-tuning">Parallel Performance, Resources, and Tuning</a><ul>
<li><a class="reference internal" href="#chunk-decomposition">Chunk Decomposition</a></li>
<li><a class="reference internal" href="#object-based">Object-Based</a></li>
<li><a class="reference internal" href="#domain-decomposition">Domain Decomposition</a></li>
</ul>
</li>
<li><a class="reference internal" href="#additional-tips">Additional Tips</a></li>
<li><a class="reference internal" href="#an-advanced-worked-example">An Advanced Worked Example</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
            
            
            
              <li class="hidden-sm"></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12">
      
  <div class="section" id="parallel-computation-with-yt">
<span id="parallel-computation"></span><h1>Parallel Computation With yt<a class="headerlink" href="#parallel-computation-with-yt" title="Permalink to this headline">¶</a></h1>
<p>yt has been instrumented with the ability to compute many &#8211; most, even &#8211;
quantities in parallel.  This utilizes the package
<a class="reference external" href="https://bitbucket.org/mpi4py/mpi4py">mpi4py</a> to parallelize using the Message
Passing Interface, typically installed on clusters.</p>
<div class="section" id="capabilities">
<span id="id1"></span><h2>Capabilities<a class="headerlink" href="#capabilities" title="Permalink to this headline">¶</a></h2>
<p>Currently, yt is able to perform the following actions in parallel:</p>
<ul class="simple">
<li>Projections (<a class="reference internal" href="../visualizing/plots.html#projection-plots"><span>Projection Plots</span></a>)</li>
<li>Slices (<a class="reference internal" href="../visualizing/plots.html#slice-plots"><span>Slice Plots</span></a>)</li>
<li>Cutting planes (oblique slices) (<a class="reference internal" href="../visualizing/plots.html#off-axis-slices"><span>Off Axis Slices</span></a>)</li>
<li>Derived Quantities (total mass, angular momentum, etc) (<a class="reference internal" href="../developing/creating_derived_quantities.html#creating-derived-quantities"><span>Creating Derived Quantities</span></a>,
<a class="reference internal" href="objects.html#derived-quantities"><span>Processing Objects: Derived Quantities</span></a>)</li>
<li>1-, 2-, and 3-D profiles (<a class="reference internal" href="generating_processed_data.html#generating-profiles-and-histograms"><span>Profiles and Histograms</span></a>)</li>
<li>Halo finding (<a class="reference internal" href="analysis_modules/halo_finders.html#halo-finding"><span>Halo Finding</span></a>)</li>
<li>Volume rendering (<a class="reference internal" href="../visualizing/volume_rendering.html#volume-rendering"><span>Volume Rendering: Making 3D Photorealistic Isocontoured Images</span></a>)</li>
<li>Isocontours &amp; flux calculations (<a class="reference internal" href="../visualizing/sketchfab.html#extracting-isocontour-information"><span>3D Surfaces and Sketchfab</span></a>)</li>
</ul>
<p>This list covers just about every action yt can take!  Additionally, almost all
scripts will benefit from parallelization with minimal modification.  The goal
of Parallel-yt has been to retain API compatibility and abstract all
parallelism.</p>
</div>
<div class="section" id="setting-up-parallel-yt">
<h2>Setting Up Parallel yt<a class="headerlink" href="#setting-up-parallel-yt" title="Permalink to this headline">¶</a></h2>
<p>To run scripts in parallel, you must first install <a class="reference external" href="https://bitbucket.org/mpi4py/mpi4py">mpi4py</a> as well as an MPI library, if one is not
already available on your system.  Instructions for doing so are provided on the
mpi4py website, but you may have luck by just running:</p>
<div class="highlight-bash"><div class="highlight"><pre><span class="nv">$ </span>pip install mpi4py
</pre></div>
</div>
<p>Once that has been installed, you&#8217;re all done!  You just need to launch your
scripts with <code class="docutils literal"><span class="pre">mpirun</span></code> (or equivalent) and signal to yt that you want to
run them in parallel by invoking the <code class="docutils literal"><span class="pre">yt.enable_parallelism()</span></code> function in
your script.  In general, that&#8217;s all it takes to get a speed benefit on a
multi-core machine.  Here is an example on an 8-core desktop:</p>
<div class="highlight-bash"><div class="highlight"><pre><span class="nv">$ </span>mpirun -np <span class="m">8</span> python script.py
</pre></div>
</div>
<p>Throughout its normal operation, yt keeps you aware of what is happening with
regular messages to the stderr usually prefaced with:</p>
<div class="highlight-bash"><div class="highlight"><pre>yt : <span class="o">[</span>INFO   <span class="o">]</span> YYY-MM-DD HH:MM:SS
</pre></div>
</div>
<p>However, when operating in parallel mode, yt outputs information from each
of your processors to this log mode, as in:</p>
<div class="highlight-bash"><div class="highlight"><pre>P000 yt : <span class="o">[</span>INFO   <span class="o">]</span> YYY-MM-DD HH:MM:SS
P001 yt : <span class="o">[</span>INFO   <span class="o">]</span> YYY-MM-DD HH:MM:SS
</pre></div>
</div>
<p>in the case of two cores being used.</p>
<p>It&#8217;s important to note that all of the processes listed in <a class="reference internal" href="#capabilities"><span>Capabilities</span></a>
work in parallel &#8211; and no additional work is necessary to parallelize those
processes.</p>
</div>
<div class="section" id="running-a-yt-script-in-parallel">
<h2>Running a yt Script in Parallel<a class="headerlink" href="#running-a-yt-script-in-parallel" title="Permalink to this headline">¶</a></h2>
<p>Many basic yt operations will run in parallel if yt&#8217;s parallelism is enabled at
startup.  For example, the following script finds the maximum density location
in the simulation and then makes a plot of the projected density:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">yt</span>
<span class="n">yt</span><span class="o">.</span><span class="n">enable_parallelism</span><span class="p">()</span>

<span class="n">ds</span> <span class="o">=</span> <span class="n">yt</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;RD0035/RedshiftOutput0035&quot;</span><span class="p">)</span>
<span class="n">v</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">find_max</span><span class="p">(</span><span class="s">&quot;density&quot;</span><span class="p">)</span>
<span class="k">print</span> <span class="n">v</span><span class="p">,</span> <span class="n">c</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">yt</span><span class="o">.</span><span class="n">ProjectionPlot</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="s">&quot;x&quot;</span><span class="p">,</span> <span class="s">&quot;density&quot;</span><span class="p">)</span>
<span class="n">p</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
</pre></div>
</div>
<p>If this script is run in parallel, two of the most expensive operations -
finding of the maximum density and the projection will be calulcated in
parallel.  If we save the script as <code class="docutils literal"><span class="pre">my_script.py</span></code>, we would run it on 16 MPI
processes using the following Bash command:</p>
<div class="highlight-bash"><div class="highlight"><pre><span class="nv">$ </span>mpirun -np <span class="m">16</span> python2.7 my_script.py
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If you run into problems, the you can use <a class="reference internal" href="../developing/debugdrive.html#remote-debugging"><span>Remote and Disconnected Debugging</span></a> to examine
what went wrong.</p>
</div>
<div class="section" id="how-do-i-run-my-yt-job-on-a-subset-of-available-processes">
<h3>How do I run my yt job on a subset of available processes<a class="headerlink" href="#how-do-i-run-my-yt-job-on-a-subset-of-available-processes" title="Permalink to this headline">¶</a></h3>
<p>You can set the <code class="docutils literal"><span class="pre">communicator</span></code> keyword in the
<code class="xref py py-func docutils literal"><span class="pre">enable_parallelism()</span></code>
call to a specific MPI communicator to specify a subset of availble MPI
processes.  If none is specified, it defaults to <code class="docutils literal"><span class="pre">COMM_WORLD</span></code>.</p>
</div>
<div class="section" id="creating-parallel-and-serial-sections-in-a-script">
<h3>Creating Parallel and Serial Sections in a Script<a class="headerlink" href="#creating-parallel-and-serial-sections-in-a-script" title="Permalink to this headline">¶</a></h3>
<p>Many yt operations will automatically run in parallel (see the next section for
a full enumeration), however some operations, particularly ones that print
output or save data to the filesystem, will be run by all processors in a
parallel script.  For example, in the script above the lines <code class="docutils literal"><span class="pre">print</span> <span class="pre">v,c</span></code> and
<code class="docutils literal"><span class="pre">p.save()</span></code> will be run on all 16 processors.  This means that your terminal
output will contain 16 repetitions of the output of the print statement and the
plot will be saved to disk 16 times (overwritten each time).</p>
<p>yt provides two convenience functions that make it easier to run most of a
script in parallel but run some subset of the script on only one processor.  The
first, <a class="reference internal" href="../reference/api/generated/yt.funcs.is_root.html#yt.funcs.is_root" title="yt.funcs.is_root"><code class="xref py py-func docutils literal"><span class="pre">is_root()</span></code></a>, returns <code class="docutils literal"><span class="pre">True</span></code> if run on the &#8216;root&#8217;
processor (the processor with MPI rank 0) and <code class="docutils literal"><span class="pre">False</span></code> otherwise.  One could
rewrite the above script to take advantage of <a class="reference internal" href="../reference/api/generated/yt.funcs.is_root.html#yt.funcs.is_root" title="yt.funcs.is_root"><code class="xref py py-func docutils literal"><span class="pre">is_root()</span></code></a> like
so:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">yt</span>
<span class="n">yt</span><span class="o">.</span><span class="n">enable_parallelism</span><span class="p">()</span>

<span class="n">ds</span> <span class="o">=</span> <span class="n">yt</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;RD0035/RedshiftOutput0035&quot;</span><span class="p">)</span>
<span class="n">v</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">find_max</span><span class="p">(</span><span class="s">&quot;density&quot;</span><span class="p">)</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">yt</span><span class="o">.</span><span class="n">ProjectionPlot</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="s">&quot;x&quot;</span><span class="p">,</span> <span class="s">&quot;density&quot;</span><span class="p">)</span>
<span class="k">if</span> <span class="n">yt</span><span class="o">.</span><span class="n">is_root</span><span class="p">():</span>
    <span class="k">print</span> <span class="n">v</span><span class="p">,</span> <span class="n">c</span>
    <span class="n">p</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
</pre></div>
</div>
<p>The second function, <a class="reference internal" href="../reference/api/generated/yt.funcs.only_on_root.html#yt.funcs.only_on_root" title="yt.funcs.only_on_root"><code class="xref py py-func docutils literal"><span class="pre">only_on_root()</span></code></a> accepts the name of a
function as well as a set of parameters and keyword arguments to pass to the
function.  This is useful when the serial component of your parallel script
would clutter the script or if you like writing your scripts as a series of
isolated function calls.  I can rewrite the example from the beginning of this
section once more using <a class="reference internal" href="../reference/api/generated/yt.funcs.only_on_root.html#yt.funcs.only_on_root" title="yt.funcs.only_on_root"><code class="xref py py-func docutils literal"><span class="pre">only_on_root()</span></code></a> to give you the flavor of
how to use it:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">yt</span>
<span class="n">yt</span><span class="o">.</span><span class="n">enable_parallelism</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">print_and_save_plot</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">plot</span><span class="p">,</span> <span class="k">print</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="k">if</span> <span class="k">print</span><span class="p">:</span>
       <span class="k">print</span> <span class="n">v</span><span class="p">,</span> <span class="n">c</span>
    <span class="n">plot</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="n">ds</span> <span class="o">=</span> <span class="n">yt</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;RD0035/RedshiftOutput0035&quot;</span><span class="p">)</span>
<span class="n">v</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">find_max</span><span class="p">(</span><span class="s">&quot;density&quot;</span><span class="p">)</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">yt</span><span class="o">.</span><span class="n">ProjectionPlot</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="s">&quot;x&quot;</span><span class="p">,</span> <span class="s">&quot;density&quot;</span><span class="p">)</span>
<span class="n">yt</span><span class="o">.</span><span class="n">only_on_root</span><span class="p">(</span><span class="n">print_and_save_plot</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">plot</span><span class="p">,</span> <span class="k">print</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="types-of-parallelism">
<h2>Types of Parallelism<a class="headerlink" href="#types-of-parallelism" title="Permalink to this headline">¶</a></h2>
<p>In order to divide up the work, yt will attempt to send different tasks to
different processors.  However, to minimize inter-process communication, yt
will decompose the information in different ways based on the task.</p>
<div class="section" id="spatial-decomposition">
<h3>Spatial Decomposition<a class="headerlink" href="#spatial-decomposition" title="Permalink to this headline">¶</a></h3>
<p>During this process, the index will be decomposed along either all three
axes or along an image plane, if the process is that of projection.  This type
of parallelism is overall less efficient than grid-based parallelism, but it
has been shown to obtain good results overall.</p>
<p>The following operations use spatial decomposition:</p>
<ul class="simple">
<li><a class="reference internal" href="analysis_modules/halo_finders.html#halo-finding"><span>Halo Finding</span></a></li>
<li><a class="reference internal" href="../visualizing/volume_rendering.html#volume-rendering"><span>Volume Rendering: Making 3D Photorealistic Isocontoured Images</span></a></li>
</ul>
</div>
<div class="section" id="grid-decomposition">
<h3>Grid Decomposition<a class="headerlink" href="#grid-decomposition" title="Permalink to this headline">¶</a></h3>
<p>The alternative to spatial decomposition is a simple round-robin of data chunks,
which could be grids, octs, or whatever chunking mechanism is used by the code
frontend begin used.  This process allows yt to pool data access to a given
data file, which ultimately results in faster read times and better parallelism.</p>
<p>The following operations use chunk decomposition:</p>
<ul class="simple">
<li>Projections (see <a class="reference internal" href="objects.html#available-objects"><span>Available Objects</span></a>)</li>
<li>Slices (see <a class="reference internal" href="objects.html#available-objects"><span>Available Objects</span></a>)</li>
<li>Cutting planes (see <a class="reference internal" href="objects.html#available-objects"><span>Available Objects</span></a>)</li>
<li>Derived Quantities (see <a class="reference internal" href="objects.html#derived-quantities"><span>Processing Objects: Derived Quantities</span></a>)</li>
<li>1-, 2-, and 3-D profiles (see <a class="reference internal" href="generating_processed_data.html#generating-profiles-and-histograms"><span>Profiles and Histograms</span></a>)</li>
<li>Isocontours &amp; flux calculations (see <a class="reference internal" href="../visualizing/sketchfab.html#surfaces"><span>3D Surfaces and Sketchfab</span></a>)</li>
</ul>
</div>
<div class="section" id="parallelization-over-multiple-objects-and-datasets">
<h3>Parallelization over Multiple Objects and Datasets<a class="headerlink" href="#parallelization-over-multiple-objects-and-datasets" title="Permalink to this headline">¶</a></h3>
<p>If you have a set of computational steps that need to apply identically and
independently to several different objects or datasets, a so-called
<a class="reference external" href="http://en.wikipedia.org/wiki/Embarrassingly_parallel">embarrassingly parallel</a>
task, yt can do that easily.  See the sections below on
<a class="reference internal" href="#parallelizing-your-analysis"><span>Parallelizing over Multiple Objects</span></a> and <a class="reference internal" href="#parallel-time-series-analysis"><span>Parallelization over Multiple Datasets (including Time Series)</span></a>.</p>
<div class="section" id="use-of-piter">
<h4>Use of <code class="docutils literal"><span class="pre">piter()</span></code><a class="headerlink" href="#use-of-piter" title="Permalink to this headline">¶</a></h4>
<p>If you use parallelism over objects or datasets, you will encounter
the <code class="docutils literal"><span class="pre">piter()</span></code> function.  <code class="docutils literal"><span class="pre">piter</span></code> is a parallel iterator, which effectively
doles out each item of a DatasetSeries object to a different processor.  In
serial processing, you might iterate over a DatasetSeries by:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="n">dataset_series</span><span class="p">:</span>
    <span class="o">&lt;</span><span class="n">process</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>But in parallel, you can use <code class="docutils literal"><span class="pre">piter()</span></code> to force each dataset to go to
a different processor:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">yt</span><span class="o">.</span><span class="n">enable_parallelism</span><span class="p">()</span>
<span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="n">dataset_series</span><span class="o">.</span><span class="n">piter</span><span class="p">():</span>
    <span class="o">&lt;</span><span class="n">process</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>In order to store information from the parallel processing step to
a data structure that exists on all of the processors operating in parallel
we offer the <code class="docutils literal"><span class="pre">storage</span></code> keyword in the <code class="docutils literal"><span class="pre">piter</span></code> function.
You may define an empty dictionary and include it as the keyword argument
<code class="docutils literal"><span class="pre">storage</span></code> to <code class="docutils literal"><span class="pre">piter()</span></code>.  Then, during the processing step, you can access
this dictionary as the <code class="docutils literal"><span class="pre">sto</span></code> object.  After the
loop is finished, the dictionary is re-aggragated from all of the processors,
and you can access the contents:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">yt</span><span class="o">.</span><span class="n">enable_parallelism</span><span class="p">()</span>
<span class="n">my_dictionary</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">sto</span><span class="p">,</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="n">dataset_series</span><span class="o">.</span><span class="n">piter</span><span class="p">(</span><span class="n">storage</span><span class="o">=</span><span class="n">my_dictionary</span><span class="p">):</span>
    <span class="o">&lt;</span><span class="n">process</span><span class="o">&gt;</span>
    <span class="n">sto</span><span class="o">.</span><span class="n">result</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">some</span> <span class="n">information</span> <span class="n">processed</span> <span class="k">for</span> <span class="n">this</span> <span class="n">dataset</span><span class="o">&gt;</span>
    <span class="n">sto</span><span class="o">.</span><span class="n">result_id</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">some</span> <span class="n">identfier</span> <span class="k">for</span> <span class="n">this</span> <span class="n">dataset</span><span class="o">&gt;</span>

<span class="k">print</span> <span class="n">my_dictionary</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="parallelizing-over-multiple-objects">
<span id="parallelizing-your-analysis"></span><h2>Parallelizing over Multiple Objects<a class="headerlink" href="#parallelizing-over-multiple-objects" title="Permalink to this headline">¶</a></h2>
<p>It is easy within yt to parallelize a list of tasks, as long as those tasks
are independent of one another. Using object-based parallelism, the function
<a class="reference internal" href="../reference/api/generated/yt.utilities.parallel_tools.parallel_analysis_interface.parallel_objects.html#yt.utilities.parallel_tools.parallel_analysis_interface.parallel_objects" title="yt.utilities.parallel_tools.parallel_analysis_interface.parallel_objects"><code class="xref py py-func docutils literal"><span class="pre">parallel_objects()</span></code></a>
will automatically split up a list of tasks over the specified number of
processors (or cores).  Please see this heavily-commented example:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="c"># As always...</span>
<span class="kn">import</span> <span class="nn">yt</span>
<span class="n">yt</span><span class="o">.</span><span class="n">enable_parallelism</span><span class="p">()</span>

<span class="kn">import</span> <span class="nn">glob</span>

<span class="c"># The number 4, below, is the number of processes to parallelize over, which</span>
<span class="c"># is generally equal to the number of MPI tasks the job is launched with.</span>
<span class="c"># If num_procs is set to zero or a negative number, the for loop below</span>
<span class="c"># will be run such that each iteration of the loop is done by a single MPI</span>
<span class="c"># task. Put another way, setting it to zero means that no matter how many</span>
<span class="c"># MPI tasks the job is run with, num_procs will default to the number of</span>
<span class="c"># MPI tasks automatically.</span>
<span class="n">num_procs</span> <span class="o">=</span> <span class="mi">4</span>

<span class="c"># fns is a list of all the simulation data files in the current directory.</span>
<span class="n">fns</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s">&quot;./plot*&quot;</span><span class="p">)</span>
<span class="n">fns</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>

<span class="c"># This dict will store information collected in the loop, below.</span>
<span class="c"># Inside the loop each task will have a local copy of the dict, but</span>
<span class="c"># the dict will be combined once the loop finishes.</span>
<span class="n">my_storage</span> <span class="o">=</span> <span class="p">{}</span>

<span class="c"># In this example, because the storage option is used in the</span>
<span class="c"># parallel_objects function, the loop yields a tuple, which gets used</span>
<span class="c"># as (sto, fn) inside the loop.</span>
<span class="c"># In the loop, sto is essentially my_storage, but a local copy of it.</span>
<span class="c"># If data does not need to be combined after the loop is done, the line</span>
<span class="c"># would look like:</span>
<span class="c">#       for fn in parallel_objects(fns, num_procs):</span>
<span class="k">for</span> <span class="n">sto</span><span class="p">,</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">yt</span><span class="o">.</span><span class="n">parallel_objects</span><span class="p">(</span><span class="n">fns</span><span class="p">,</span> <span class="n">num_procs</span><span class="p">,</span> <span class="n">storage</span> <span class="o">=</span> <span class="n">my_storage</span><span class="p">):</span>

    <span class="c"># Open a data file, remembering that fn is different on each task.</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">yt</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
    <span class="n">dd</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">all_data</span><span class="p">()</span>

    <span class="c"># This copies fn and the min/max of density to the local copy of</span>
    <span class="c"># my_storage</span>
    <span class="n">sto</span><span class="o">.</span><span class="n">result_id</span> <span class="o">=</span> <span class="n">fn</span>
    <span class="n">sto</span><span class="o">.</span><span class="n">result</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">quantities</span><span class="o">.</span><span class="n">extrema</span><span class="p">(</span><span class="s">&quot;density&quot;</span><span class="p">)</span>

    <span class="c"># Makes and saves a plot of the gas density.</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">yt</span><span class="o">.</span><span class="n">ProjectionPlot</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="s">&quot;x&quot;</span><span class="p">,</span> <span class="s">&quot;density&quot;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="c"># At this point, as the loop exits, the local copies of my_storage are</span>
<span class="c"># combined such that all tasks now have an identical and full version of</span>
<span class="c"># my_storage. Until this point, each task is unaware of what the other</span>
<span class="c"># tasks have produced.</span>
<span class="c"># Below, the values in my_storage are printed by only one task. The other</span>
<span class="c"># tasks do nothing.</span>
<span class="k">if</span> <span class="n">yt</span><span class="o">.</span><span class="n">is_root</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">fn</span><span class="p">,</span> <span class="n">vals</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">my_storage</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
        <span class="k">print</span> <span class="n">fn</span><span class="p">,</span> <span class="n">vals</span>
</pre></div>
</div>
<p>This example above can be modified to loop over anything that can be saved to
a Python list: halos, data files, arrays, and more.</p>
</div>
<div class="section" id="parallelization-over-multiple-datasets-including-time-series">
<span id="parallel-time-series-analysis"></span><h2>Parallelization over Multiple Datasets (including Time Series)<a class="headerlink" href="#parallelization-over-multiple-datasets-including-time-series" title="Permalink to this headline">¶</a></h2>
<p>The same <code class="docutils literal"><span class="pre">parallel_objects</span></code> machinery discussed above is turned on by
default when using a <a class="reference internal" href="../reference/api/generated/yt.data_objects.time_series.DatasetSeries.html#yt.data_objects.time_series.DatasetSeries" title="yt.data_objects.time_series.DatasetSeries"><code class="xref py py-class docutils literal"><span class="pre">DatasetSeries</span></code></a> object
(see <a class="reference internal" href="time_series_analysis.html#time-series-analysis"><span>Time Series Analysis</span></a>) to iterate over simulation outputs.  The
syntax for this is very simple.  As an example, we can use the following script
to find the angular momentum vector in a 1 pc sphere centered on the maximum
density cell in a large number of simulation outputs:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">yt</span>
<span class="n">yt</span><span class="o">.</span><span class="n">enable_parallelism</span><span class="p">()</span>

<span class="c"># Load all of the DD*/output_* files into a DatasetSeries object</span>
<span class="c"># in this case it is a Time Series</span>
<span class="n">ts</span> <span class="o">=</span> <span class="n">yt</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;DD*/output_*&quot;</span><span class="p">)</span>

<span class="c"># Define an empty storage dictionary for collecting information</span>
<span class="c"># in parallel through processing</span>
<span class="n">storage</span> <span class="o">=</span> <span class="p">{}</span>

<span class="c"># Use piter() to iterate over the time series, one proc per dataset</span>
<span class="c"># and store the resulting information from each dataset in</span>
<span class="c"># the storage dictionary</span>
<span class="k">for</span> <span class="n">sto</span><span class="p">,</span> <span class="n">ds</span> <span class="ow">in</span> <span class="n">ts</span><span class="o">.</span><span class="n">piter</span><span class="p">(</span><span class="n">storage</span><span class="o">=</span><span class="n">storage</span><span class="p">):</span>
    <span class="n">sphere</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">sphere</span><span class="p">(</span><span class="s">&quot;max&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="s">&quot;pc&quot;</span><span class="p">))</span>
    <span class="n">sto</span><span class="o">.</span><span class="n">result</span> <span class="o">=</span> <span class="n">sphere</span><span class="o">.</span><span class="n">quantities</span><span class="o">.</span><span class="n">angular_momentum_vector</span><span class="p">()</span>
    <span class="n">sto</span><span class="o">.</span><span class="n">result_id</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">ds</span><span class="p">)</span>

<span class="c"># Print out the angular momentum vector for all of the datasets</span>
<span class="k">for</span> <span class="n">L</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">storage</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
    <span class="k">print</span> <span class="n">L</span>
</pre></div>
</div>
<p>Note that this script can be run in serial or parallel with an arbitrary number
of processors.  When running in parallel, each output is given to a different
processor.</p>
<p>You can also request a fixed number of processors to calculate each
angular momentum vector.  For example, the following script will calculate each
angular momentum vector using 4 workgroups, splitting up the pool available
processors.  Note that parallel=1 implies that the analysis will be run using
1 workgroup, whereas parallel=True will run with Nprocs workgroups.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">yt</span>
<span class="n">yt</span><span class="o">.</span><span class="n">enable_parallelism</span><span class="p">()</span>

<span class="n">ts</span> <span class="o">=</span> <span class="n">yt</span><span class="o">.</span><span class="n">DatasetSeries</span><span class="p">(</span><span class="s">&quot;DD*/output_*&quot;</span><span class="p">,</span> <span class="n">parallel</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span>

<span class="k">for</span> <span class="n">ds</span> <span class="ow">in</span> <span class="n">ts</span><span class="o">.</span><span class="n">piter</span><span class="p">():</span>
    <span class="n">sphere</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">sphere</span><span class="p">(</span><span class="s">&quot;max&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="s">&quot;pc))</span>
    <span class="n">L_vecs</span> <span class="o">=</span> <span class="n">sphere</span><span class="o">.</span><span class="n">quantities</span><span class="o">.</span><span class="n">angular_momentum_vector</span><span class="p">()</span>
</pre></div>
</div>
<p>If you do not want to use <code class="docutils literal"><span class="pre">parallel_objects</span></code> parallelism when using a
DatasetSeries object, set <code class="docutils literal"><span class="pre">parallel</span> <span class="pre">=</span> <span class="pre">False</span></code>.  When running python in parallel,
this will use all of the available processors to evaluate the requested
operation on each simulation output.  Some care and possibly trial and error
might be necessary to estimate the correct settings for your simulation
outputs.</p>
</div>
<div class="section" id="parallel-performance-resources-and-tuning">
<h2>Parallel Performance, Resources, and Tuning<a class="headerlink" href="#parallel-performance-resources-and-tuning" title="Permalink to this headline">¶</a></h2>
<p>Optimizing parallel jobs in yt is difficult; there are many parameters that
affect how well and quickly the job runs.  In many cases, the only way to find
out what the minimum (or optimal) number of processors is, or amount of memory
needed, is through trial and error.  However, this section will attempt to
provide some insight into what are good starting values for a given parallel
task.</p>
<div class="section" id="chunk-decomposition">
<h3>Chunk Decomposition<a class="headerlink" href="#chunk-decomposition" title="Permalink to this headline">¶</a></h3>
<p>In general, these types of parallel calculations scale very well with number of
processors.  They are also fairly memory-conservative.  The two limiting factors
is therefore the number of chunks in the dataset, and the speed of the disk the
data is stored on.  There is no point in running a parallel job of this kind
with more processors than chunks, because the extra processors will do absolutely
nothing, and will in fact probably just serve to slow down the whole calculation
due to the extra overhead.  The speed of the disk is also a consideration - if
it is not a high-end parallel file system, adding more tasks will not speed up
the calculation if the disk is already swamped with activity.</p>
<p>The best advice for these sort of calculations is to run with just a few
processors and go from there, seeing if it the runtime improves noticeably.</p>
<p><strong>Projections, Slices, and Cutting Planes</strong></p>
<p>Projections, slices and cutting planes are the most common methods of creating
two-dimensional representations of data.  All three have been parallelized in a
chunk-based fashion.</p>
<ul class="simple">
<li><strong>Projections</strong>: projections are parallelized utilizing a quad-tree approach.
Data is loaded for each processor, typically by a process that consolidates
open/close/read operations, and each grid is then iterated over and cells are
deposited into a data structure that stores values corresponding to positions
in the two-dimensional plane.  This provides excellent load balancing, and in
serial is quite fast.  However, the operation by which quadtrees are joined
across processors scales poorly; while memory consumption scales well, the
time to completion does not.  As such, projections can often be done very
fast when operating only on a single processor!  The quadtree algorithm can
be used inline (and, indeed, it is for this reason that it is slow.)  It is
recommended that you attempt to project in serial before projecting in
parallel; even for the very largest datasets (Enzo 1024^3 root grid with 7
levels of refinement) in the absence of IO the quadtree algorithm takes only
three minutes or so on a decent processor.</li>
<li><strong>Slices</strong>: to generate a slice, chunks that intersect a given slice are iterated
over and their finest-resolution cells are deposited.  The chunks are
decomposed via standard load balancing.  While this operation is parallel,
<strong>it is almost never necessary to slice a dataset in parallel</strong>, as all data is
loaded on demand anyway.  The slice operation has been parallelized so as to
enable slicing when running <em>in situ</em>.</li>
<li><strong>Cutting planes</strong>: cutting planes are parallelized exactly as slices are.
However, in contrast to slices, because the data-selection operation can be
much more time consuming, cutting planes often benefit from parallelism.</li>
</ul>
</div>
<div class="section" id="object-based">
<h3>Object-Based<a class="headerlink" href="#object-based" title="Permalink to this headline">¶</a></h3>
<p>Like chunk decomposition, it does not help to run with more processors than the
number of objects to be iterated over.
There is also the matter of the kind of work being done on each object, and
whether it is disk-intensive, cpu-intensive, or memory-intensive.
It is up to the user to figure out what limits the performance of their script,
and use the correct amount of resources, accordingly.</p>
<p>Disk-intensive jobs are limited by the speed of the file system, as above,
and extra processors beyond its capability are likely counter-productive.
It may require some testing or research (e.g. supercomputer documentation)
to find out what the file system is capable of.</p>
<p>If it is cpu-intensive, it&#8217;s best to use as many processors as possible
and practical.</p>
<p>For a memory-intensive job, each processor needs to be able to allocate enough
memory, which may mean using fewer than the maximum number of tasks per compute
node, and increasing the number of nodes.
The memory used per processor should be calculated, compared to the memory
on each compute node, which dictates how many tasks per node.
After that, the number of processors used overall is dictated by the
disk system or CPU-intensity of the job.</p>
</div>
<div class="section" id="domain-decomposition">
<h3>Domain Decomposition<a class="headerlink" href="#domain-decomposition" title="Permalink to this headline">¶</a></h3>
<p>The various types of analysis that utilize domain decomposition use them in
different enough ways that they are be discussed separately.</p>
<p><strong>Halo-Finding</strong></p>
<p>Halo finding, along with the merger tree that uses halo finding, operates on the
particles in the volume, and is therefore mostly chunk-agnostic.  Generally, the
biggest concern for halo finding is the amount of memory needed.  There is
subtle art in estimating the amount of memory needed for halo finding, but a
rule of thumb is that the HOP halo finder is the most memory intensive
(<code class="xref py py-func docutils literal"><span class="pre">HaloFinder()</span></code>), and Friends of Friends (<code class="xref py py-func docutils literal"><span class="pre">FOFHaloFinder()</span></code>) being the
most memory-conservative.  It has been found that <code class="xref py py-func docutils literal"><span class="pre">parallelHF()</span></code> needs
roughly 1 MB of memory per 5,000 particles, although recent work has improved
this and the memory requirement is now smaller than this. But this is a good
starting point for beginning to calculate the memory required for halo-finding.
For more information, see <a class="reference internal" href="analysis_modules/halo_finders.html#halo-finding"><span>Halo Finding</span></a>.</p>
<p><strong>Volume Rendering</strong></p>
<p>The simplest way to think about volume rendering, is that it load-balances over
the i/o chunks in the dataset.  Each processor is given roughly the same sized
volume to operate on.  In practice, there are just a few things to keep in mind
when doing volume rendering.  First, it only uses a power of two number of
processors.  If the job is run with 100 processors, only 64 of them will
actually do anything.  Second, the absolute maximum number of processors is the
number of chunks.  In order to keep work distributed evenly, typically the
number of processors should be no greater than one-eighth or one-quarter the
number of processors that were used to produce the dataset.
For more information, see <a class="reference internal" href="../visualizing/volume_rendering.html#volume-rendering"><span>Volume Rendering: Making 3D Photorealistic Isocontoured Images</span></a>.</p>
</div>
</div>
<div class="section" id="additional-tips">
<h2>Additional Tips<a class="headerlink" href="#additional-tips" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Don&#8217;t be afraid to change how a parallel job is run. Change the
number of processors, or memory allocated, and see if things work better
or worse. After all, it&#8217;s just a computer, it doesn&#8217;t pass moral judgment!</li>
<li>Similarly, human time is more valuable than computer time. Try increasing
the number of processors, and see if the runtime drops significantly.
There will be a sweet spot between speed of run and the waiting time in
the job scheduler queue; it may be worth trying to find it.</li>
<li>If you are using object-based parallelism but doing CPU-intensive computations
on each object, you may find that setting <code class="docutils literal"><span class="pre">num_procs</span></code> equal to the
number of processors per compute node can lead to significant speedups.
By default, most mpi implementations will assign tasks to processors on a
&#8216;by-slot&#8217; basis, so this setting will tell yt to do computations on a single
object using only the processors on a single compute node.  A nice application
for this type of parallelism is calculating a list of derived quantities for
a large number of simulation outputs.</li>
<li>It is impossible to tune a parallel operation without understanding what&#8217;s
going on. Read the documentation, look at the underlying code, or talk to
other yt users. Get informed!</li>
<li>Sometimes it is difficult to know if a job is cpu, memory, or disk
intensive, especially if the parallel job utilizes several of the kinds of
parallelism discussed above. In this case, it may be worthwhile to put
some simple timers in your script (as below) around different parts.</li>
</ul>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">yt</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="n">yt</span><span class="o">.</span><span class="n">enable_parallelism</span><span class="p">()</span>

<span class="n">ds</span> <span class="o">=</span> <span class="n">yt</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;DD0152&quot;</span><span class="p">)</span>
<span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">bigstuff</span><span class="p">,</span> <span class="n">hugestuff</span> <span class="o">=</span> <span class="n">StuffFinder</span><span class="p">(</span><span class="n">ds</span><span class="p">)</span>
<span class="n">BigHugeStuffParallelFunction</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="n">bigstuff</span><span class="p">,</span> <span class="n">hugestuff</span><span class="p">)</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000000</span><span class="p">):</span>
    <span class="n">tinystuff</span><span class="p">,</span> <span class="n">ministuff</span> <span class="o">=</span> <span class="n">GetTinyMiniStuffOffDisk</span><span class="p">(</span><span class="s">&quot;in</span><span class="si">%06d</span><span class="s">.txt&quot;</span> <span class="o">%</span> <span class="n">i</span><span class="p">)</span>
    <span class="n">array</span> <span class="o">=</span> <span class="n">TinyTeensyParallelFunction</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="n">tinystuff</span><span class="p">,</span> <span class="n">ministuff</span><span class="p">)</span>
    <span class="n">SaveTinyMiniStuffToDisk</span><span class="p">(</span><span class="s">&quot;out</span><span class="si">%06d</span><span class="s">.txt&quot;</span> <span class="o">%</span> <span class="n">i</span><span class="p">,</span> <span class="n">array</span><span class="p">)</span>
<span class="n">t2</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="k">if</span> <span class="n">yt</span><span class="o">.</span><span class="n">is_root</span><span class="p">()</span>
    <span class="k">print</span> <span class="s">&quot;BigStuff took </span><span class="si">%.5e</span><span class="s"> sec, TinyStuff took </span><span class="si">%.5e</span><span class="s"> sec&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">t1</span> <span class="o">-</span> <span class="n">t0</span><span class="p">,</span> <span class="n">t2</span> <span class="o">-</span> <span class="n">t1</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li>Remember that if the script handles disk IO explicitly, and does not use
a built-in yt function to write data to disk,
care must be taken to
avoid <a class="reference external" href="http://en.wikipedia.org/wiki/Race_conditions">race-conditions</a>.
Be explicit about which MPI task writes to disk using a construction
something like this:</li>
</ul>
<div class="highlight-python"><div class="highlight"><pre><span class="k">if</span> <span class="n">yt</span><span class="o">.</span><span class="n">is_root</span><span class="p">()</span>
    <span class="nb">file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s">&quot;out.txt&quot;</span><span class="p">,</span> <span class="s">&quot;w&quot;</span><span class="p">)</span>
    <span class="nb">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">stuff</span><span class="p">)</span>
    <span class="nb">file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<ul class="simple">
<li>Many supercomputers allow users to ssh into the nodes that their job is
running on.
Many job schedulers send the names of the nodes that are
used in the notification emails, or a command like <code class="docutils literal"><span class="pre">qstat</span> <span class="pre">-f</span> <span class="pre">NNNN</span></code>, where
<code class="docutils literal"><span class="pre">NNNN</span></code> is the job ID, will also show this information.
By ssh-ing into nodes, the memory usage of each task can be viewed in
real-time as the job runs (using <code class="docutils literal"><span class="pre">top</span></code>, for example),
and can give valuable feedback about the
resources the task requires.</li>
</ul>
</div>
<div class="section" id="an-advanced-worked-example">
<h2>An Advanced Worked Example<a class="headerlink" href="#an-advanced-worked-example" title="Permalink to this headline">¶</a></h2>
<p>Below is a script used to calculate the redshift of first 99.9% ionization in a
simulation.  This script was designed to analyze a set of 100 outputs on
Gordon, running on 128 processors.  This script goes through three phases:</p>
<ol class="arabic simple">
<li>Define a new derived field, which calculates the fraction of ionized
hydrogen as a function only of the total hydrogen density.</li>
<li>Load a time series up, specifying <code class="docutils literal"><span class="pre">parallel</span> <span class="pre">=</span> <span class="pre">8</span></code>.  This means that it
will decompose into 8 jobs.  So if we ran on 128 processors, we would have
16 processors assigned to each output in the time series.</li>
<li>Creating a big cube that will hold our results for this set of processors.
Note that this will be only for each output considered by this processor,
and this cube will not necessarily be filled in in every cell.</li>
<li>For each output, distribute the grids to each of the sixteen processors
working on that output.  Each of these takes the max of the ionized
redshift in their zone versus the accumulation cube.</li>
<li>Iterate over slabs and find the maximum redshift in each slab of our
accumulation cube.</li>
</ol>
<p>At the end, the root processor (of the global calculation) writes out an
ionization cube that contains the redshift of first reionization for each zone
across all outputs.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">yt</span>
<span class="kn">from</span> <span class="nn">yt.utilities.parallel_tools.parallel_analysis_interface</span> \
    <span class="kn">import</span> <span class="n">communication_system</span>

<span class="kn">import</span> <span class="nn">h5py</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="nd">@yt.derived_field</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">&quot;IonizedHydrogen&quot;</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="s">&quot;&quot;</span><span class="p">,</span>
                  <span class="n">display_name</span><span class="o">=</span><span class="s">r&quot;\frac{\rho_{HII}}{\rho_H}&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">IonizedHydrogen</span><span class="p">(</span><span class="n">field</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">data</span><span class="p">[</span><span class="s">&quot;HII_Density&quot;</span><span class="p">]</span><span class="o">/</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">&quot;HI_Density&quot;</span><span class="p">]</span><span class="o">+</span><span class="n">data</span><span class="p">[</span><span class="s">&quot;HII_Density&quot;</span><span class="p">])</span>

<span class="n">ts</span> <span class="o">=</span> <span class="n">yt</span><span class="o">.</span><span class="n">DatasetSeries</span><span class="p">(</span><span class="s">&quot;SED800/DD*/*.index&quot;</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

<span class="n">ionized_z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">ts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">domain_dimensions</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s">&quot;float32&quot;</span><span class="p">)</span>

<span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">for</span> <span class="n">ds</span> <span class="ow">in</span> <span class="n">ts</span><span class="o">.</span><span class="n">piter</span><span class="p">():</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">current_redshift</span>
    <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">parallel_objects</span><span class="p">(</span><span class="n">ds</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">grids</span><span class="p">,</span> <span class="n">njobs</span> <span class="o">=</span> <span class="mi">16</span><span class="p">):</span>
        <span class="n">i1</span><span class="p">,</span> <span class="n">j1</span><span class="p">,</span> <span class="n">k1</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_global_startindex</span><span class="p">()</span> <span class="c"># Index into our domain</span>
        <span class="n">i2</span><span class="p">,</span> <span class="n">j2</span><span class="p">,</span> <span class="n">k2</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_global_startindex</span><span class="p">()</span> <span class="o">+</span> <span class="n">g</span><span class="o">.</span><span class="n">ActiveDimensions</span>
        <span class="c"># Look for the newly ionized gas</span>
        <span class="n">newly_ion</span> <span class="o">=</span> <span class="p">((</span><span class="n">g</span><span class="p">[</span><span class="s">&quot;IonizedHydrogen&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.999</span><span class="p">)</span>
                   <span class="o">&amp;</span> <span class="p">(</span><span class="n">ionized_z</span><span class="p">[</span><span class="n">i1</span><span class="p">:</span><span class="n">i2</span><span class="p">,</span><span class="n">j1</span><span class="p">:</span><span class="n">j2</span><span class="p">,</span><span class="n">k1</span><span class="p">:</span><span class="n">k2</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">z</span><span class="p">))</span>
        <span class="n">ionized_z</span><span class="p">[</span><span class="n">i1</span><span class="p">:</span><span class="n">i2</span><span class="p">,</span><span class="n">j1</span><span class="p">:</span><span class="n">j2</span><span class="p">,</span><span class="n">k1</span><span class="p">:</span><span class="n">k2</span><span class="p">][</span><span class="n">newly_ion</span><span class="p">]</span> <span class="o">=</span> <span class="n">z</span>
        <span class="n">g</span><span class="o">.</span><span class="n">clear_data</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s">&quot;Iteration completed  </span><span class="si">%0.3e</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">t1</span><span class="p">))</span>
<span class="n">comm</span> <span class="o">=</span> <span class="n">communication_system</span><span class="o">.</span><span class="n">communicators</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ionized_z</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">ionized_z</span><span class="p">[</span><span class="n">i</span><span class="p">,:,:]</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">mpi_allreduce</span><span class="p">(</span><span class="n">ionized_z</span><span class="p">[</span><span class="n">i</span><span class="p">,:,:],</span> <span class="n">op</span><span class="o">=</span><span class="s">&quot;max&quot;</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">&quot;Slab </span><span class="si">% 3i</span><span class="s"> has minimum z of </span><span class="si">%0.3e</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">ionized_z</span><span class="p">[</span><span class="n">i</span><span class="p">,:,:]</span><span class="o">.</span><span class="n">max</span><span class="p">()))</span>
<span class="n">t2</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;Completed.  </span><span class="si">%0.3e</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">t2</span><span class="o">-</span><span class="n">t1</span><span class="p">))</span>

<span class="k">if</span> <span class="n">comm</span><span class="o">.</span><span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="s">&quot;IonizationCube.h5&quot;</span><span class="p">,</span> <span class="s">&quot;w&quot;</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">create_dataset</span><span class="p">(</span><span class="s">&quot;/z&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">ionized_z</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>


    </div>
      
  </div>
</div>
    <div class="footer">
      &copy; Copyright 2013, the yt Project.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.3.1.
    </div>
  </body>
</html>